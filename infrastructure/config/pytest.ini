[pytest]
testpaths = src/backend/tests src/web/tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

addopts = --strict-markers -v --cov=mfe --cov-report=term-missing --cov-report=html --benchmark-only --benchmark-storage=.benchmarks --benchmark-autosave --memray --memray-threshold=100MB

markers =
    asyncio: mark test as async/await test
    benchmark: mark test as performance benchmark
    slow: mark test as slow running (>30s)
    numba: mark test as requiring Numba optimization
    numba_parallel: mark test as using parallel Numba optimization
    hypothesis: mark test as property-based test
    distribution: mark test as distribution property test
    memray: mark test for memory profiling
    high_memory: mark test as memory intensive

# Plugin configurations
cov_fail_under = 90

benchmark_min_rounds = 100
benchmark_warmup = True
benchmark_timer = time.perf_counter
benchmark_disable_gc = True

asyncio_mode = auto

memray_threshold = 100MB
memray_output = html